{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01fd45bd-1a1b-472d-b95c-093d7065abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow_probability.python.math import random_rademacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66efd9c-11e7-4ba0-82c4-682f4f690658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/flattened_data.csv\", index_col = \"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f992189c-63d8-4954-a1b9-8f27229a67e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1INCHBUSD_open      float64\n",
       "1INCHBUSD_high      float64\n",
       "1INCHBUSD_low       float64\n",
       "1INCHBUSD_close     float64\n",
       "1INCHBUSD_volume    float64\n",
       "                     ...   \n",
       "ZRXUSD_open         float64\n",
       "ZRXUSD_high         float64\n",
       "ZRXUSD_low          float64\n",
       "ZRXUSD_close        float64\n",
       "ZRXUSD_volume       float64\n",
       "Length: 1955, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf772e5-eb67-49b5-a765-3cbc3833ac29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3624, 1955)\n",
      "(3624, 391)\n",
      "391\n"
     ]
    }
   ],
   "source": [
    "# check if market bearish\n",
    "df2 = df.copy()\n",
    "print(df.shape)\n",
    "ilist = []\n",
    "for i in range(len(df.columns)):\n",
    "    if i%5!=3:\n",
    "        ilist.append(i)\n",
    "df2 = df2.drop(df.columns[ilist],axis = 1)\n",
    "print(df2.shape)\n",
    "price_list = df2.iloc[0]\n",
    "print(len(price_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9239ac-261b-4dd2-8c5a-46722d41cd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       1INCHBUSD_open  1INCHBUSD_high  1INCHBUSD_low  1INCHBUSD_close  \\\n",
       "0              2.410           2.450          2.406            2.429   \n",
       "1              2.434           2.441          2.421            2.424   \n",
       "2              2.423           2.444          2.418            2.434   \n",
       "3              2.433           2.449          2.433            2.435   \n",
       "4              2.436           2.454          2.415            2.428   \n",
       "...              ...             ...            ...              ...   \n",
       "3619           0.967           0.972          0.953            0.964   \n",
       "3620           0.963           0.965          0.960            0.965   \n",
       "3621           0.964           0.964          0.958            0.961   \n",
       "3622           0.960           0.966          0.953            0.965   \n",
       "3623           0.965           0.981          0.961            0.978   \n",
       "\n",
       "      1INCHBUSD_volume  1INCHUSD_open  1INCHUSD_high  1INCHUSD_low  \\\n",
       "0              27034.1          2.390          2.420         2.390   \n",
       "1              15641.5          2.420          2.440         2.410   \n",
       "2              10500.5          2.430          2.450         2.430   \n",
       "3              11621.9          2.430          2.450         2.430   \n",
       "4              18122.9          2.420          2.430         2.400   \n",
       "...                ...            ...            ...           ...   \n",
       "3619           62571.4          0.966          0.972         0.966   \n",
       "3620           19140.8          0.969          0.970         0.966   \n",
       "3621           15210.7          0.969          0.970         0.967   \n",
       "3622           35818.9          0.967          0.971         0.967   \n",
       "3623           27142.4          0.972          0.972         0.966   \n",
       "\n",
       "      1INCHUSD_close  1INCHUSD_volume  ...  ZRXBUSD_open  ZRXBUSD_high  \\\n",
       "0              2.420         47726.30  ...        0.8225        0.8375   \n",
       "1              2.440        109643.15  ...        0.8367        0.8367   \n",
       "2              2.440         22534.85  ...        0.8249        0.8305   \n",
       "3              2.430         16066.99  ...        0.8310        0.8327   \n",
       "4              2.400         35143.16  ...        0.8262        0.8326   \n",
       "...              ...              ...  ...           ...           ...   \n",
       "3619           0.969         34241.32  ...        0.4214        0.4370   \n",
       "3620           0.968          5846.26  ...        0.4270        0.4432   \n",
       "3621           0.969          5068.87  ...        0.4295        0.4445   \n",
       "3622           0.971           786.32  ...        0.4385        0.4395   \n",
       "3623           0.967         10317.00  ...        0.4289        0.4363   \n",
       "\n",
       "      ZRXBUSD_low  ZRXBUSD_close  ZRXBUSD_volume  ZRXUSD_open  ZRXUSD_high  \\\n",
       "0          0.8225         0.8349          2957.0     0.803274     0.815819   \n",
       "1          0.8262         0.8262          7690.0     0.815761     0.818488   \n",
       "2          0.8249         0.8296          1352.0     0.817332     0.841967   \n",
       "3          0.8271         0.8271          5814.0     0.825479     0.826189   \n",
       "4          0.8239         0.8326          4731.0     0.822383     0.824401   \n",
       "...           ...            ...             ...          ...          ...   \n",
       "3619       0.4193         0.4309        118348.0     0.415042     0.417221   \n",
       "3620       0.4252         0.4308        148208.0     0.414923     0.421796   \n",
       "3621       0.4295         0.4410        149321.0     0.421837     0.421837   \n",
       "3622       0.4250         0.4289        105858.0     0.417112     0.421681   \n",
       "3623       0.4231         0.4324        135402.0     0.420771     0.423000   \n",
       "\n",
       "      ZRXUSD_low  ZRXUSD_close  ZRXUSD_volume  \n",
       "0       0.803274      0.815819   124094.48027  \n",
       "1       0.812232      0.816939   430003.38704  \n",
       "2       0.816370      0.825341   545121.67633  \n",
       "3       0.819242      0.821205   174704.12975  \n",
       "4       0.814999      0.821184   109516.28991  \n",
       "...          ...           ...            ...  \n",
       "3619    0.412115      0.414259   146124.40386  \n",
       "3620    0.414923      0.421796    48940.19297  \n",
       "3621    0.416822      0.417250    35316.14544  \n",
       "3622    0.416555      0.420949    34868.68387  \n",
       "3623    0.417373      0.420407    78304.47144  \n",
       "\n",
       "[3624 rows x 1955 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data ¯\\_(ツ)_/¯\n",
    "x = df.values #returns a numpy array\n",
    "df = pd.DataFrame(x, columns = df.columns)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc41b3f1-85f3-44eb-be03-beb4ab397a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2537, 1955)\n",
      "Validation set shape: (544, 1955)\n",
      "Test data set: (543, 1955)\n"
     ]
    }
   ],
   "source": [
    "## split the dataset into 70:15:15\n",
    "last_15 = sorted(df.index.values)[-int(0.15*len(df))] # Last 15% indices\n",
    "last_30 = sorted(df.index.values)[-int(0.3*len(df))] \n",
    "\n",
    "train_data = df[(df.index < last_30)].values\n",
    "val_data = df[(df.index >= last_30) & (df.index < last_15)].values\n",
    "test_data = df[(df.index >= last_15)].values\n",
    "\n",
    "print('Training set shape: {}'.format(train_data.shape))\n",
    "print('Validation set shape: {}'.format(val_data.shape))\n",
    "print('Test data set: {}'.format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb560acf-fb70-4a41-9b65-c2be69119232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "val_data_scaled = scaler.transform(val_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9447462-581c-4b9f-908d-90f5aa3ca34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (2201, 336, 1955) (2201, 1955)\n",
      "Validation set shape (208, 336, 1955) (208, 1955)\n",
      "Testing set shape (207, 336, 1955) (207, 1955)\n",
      "(3624, 1955)\n"
     ]
    }
   ],
   "source": [
    "# reshape the data with to window size\n",
    "seq_len = 336 #30\n",
    "\n",
    "def reshape_data(seq_len, data):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_len, len(data)):\n",
    "        X.append(data[i-seq_len:i])\n",
    "        y.append(data[:][i])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "x_train, y_train = reshape_data(seq_len, train_data)\n",
    "x_val, y_val = reshape_data(seq_len, val_data)\n",
    "x_test, y_test = reshape_data(seq_len, test_data)\n",
    "\n",
    "print('Training set shape', x_train.shape, y_train.shape)\n",
    "print('Validation set shape', x_val.shape, y_val.shape)\n",
    "print('Testing set shape' ,x_test.shape, y_test.shape)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf1d763-6cfd-452e-a418-5036cf19534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 1955)\n",
      "(207, 391)\n",
      "(207, 391)\n",
      "5936.3470905793765\n"
     ]
    }
   ],
   "source": [
    "profit = 0\n",
    "x_test_last = x_test[:, -1, :]\n",
    "\n",
    "print(x_test_last.shape)\n",
    "x_test_last_close = []\n",
    "y_test_close = []\n",
    "y_test_pred_close = []\n",
    "for i in range(x_test_last.shape[1]):\n",
    "    if i%5 ==3:\n",
    "        x_test_last_close.append(x_test_last[:,i])\n",
    "        y_test_close.append(y_test[:,i])\n",
    "        # y_test_pred_close.append(y_test_pred[:,i])\n",
    "x_test_last_close = np.transpose(np.array(x_test_last_close))\n",
    "y_test_close = np.transpose(np.array(y_test_close))\n",
    "# y_test_pred_close = np.transpose(np.array(y_test_pred_close))\n",
    "print(x_test_last_close.shape)\n",
    "print(y_test_close.shape)\n",
    "# print(y_test_pred_close.shape)\n",
    "\n",
    "loss_money = 0\n",
    "profit_money = 0\n",
    "for i in range(x_test_last_close.shape[0]):\n",
    "    for j in range(x_test_last_close.shape[1]):\n",
    "        if x_test_last_close[i,j] != 0:\n",
    "            profit = profit - 1000 + 1000*(y_test_close[i, j]/x_test_last_close[i,j])\n",
    "print(profit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95292b25-e65f-4dcc-a29b-83792cd26a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCHS = 100\n",
    "\n",
    "# Learning rate\n",
    "L_RATE = 1e-4\n",
    "\n",
    "# Proportion of samples to hold out\n",
    "VAL_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a25ce57e-e01f-4033-a4a0-ec855b4d0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier initializer\n",
    "def xavier(shape):\n",
    "    return tf.random.truncated_normal(\n",
    "        shape, \n",
    "        mean=0.0,\n",
    "        stddev=np.sqrt(2/sum(shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd994f6-ebf5-4fb6-95d6-35ef47ebd680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDenseLayer(tf.keras.Model):\n",
    "    \"\"\"A fully-connected Bayesian neural network layer\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d_in : int\n",
    "        Dimensionality of the input (# input features)\n",
    "    d_out : int\n",
    "        Output dimensionality (# units in the layer)\n",
    "    name : str\n",
    "        Name for the layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    weight : tensorflow_probability.distributions.Normal\n",
    "        Variational distributions for the network weights\n",
    "    bias : tensorflow_probability.distributions.Normal\n",
    "        Variational distributions for the network biases\n",
    "    losses : tensorflow.Tensor\n",
    "        Sum of the Kullback–Leibler divergences between\n",
    "        the posterior distributions and their priors\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    call : tensorflow.Tensor\n",
    "        Perform the forward pass of the data through\n",
    "        the layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out, name=None):\n",
    "        super(BayesianDenseLayer, self).__init__(name=name)\n",
    "        self.w_loc = tf.Variable(xavier([d_in, d_out]), name='w_loc')\n",
    "        self.w_std = tf.Variable(xavier([d_in, d_out])-6.0, name='w_std')\n",
    "        self.b_loc = tf.Variable(xavier([1, d_out]), name='b_loc')\n",
    "        self.b_std = tf.Variable(xavier([1, d_out])-6.0, name='b_std')\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def weight(self):\n",
    "        return tfd.Normal(self.w_loc, tf.nn.softplus(self.w_std))\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def bias(self):\n",
    "        return tfd.Normal(self.b_loc, tf.nn.softplus(self.b_std))\n",
    "        \n",
    "        \n",
    "    def call(self, x, sampling=True):\n",
    "        if sampling:\n",
    "            return x @ self.weight.sample() + self.bias.sample()        \n",
    "        else:\n",
    "            return x @ self.w_loc + self.b_loc\n",
    "            \n",
    "            \n",
    "    @property\n",
    "    def losses(self):\n",
    "        prior = tfd.Normal(0, 1)\n",
    "        return (tf.reduce_sum(tfd.kl_divergence(self.weight, prior)) +\n",
    "                tf.reduce_sum(tfd.kl_divergence(self.bias, prior)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c510940f-c88a-4223-bda3-581a20b2cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDenseLayer(tf.keras.Model):\n",
    "    \"\"\"A fully-connected Bayesian neural network layer\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d_in : int\n",
    "        Dimensionality of the input (# input features)\n",
    "    d_out : int\n",
    "        Output dimensionality (# units in the layer)\n",
    "    name : str\n",
    "        Name for the layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    losses : tensorflow.Tensor\n",
    "        Sum of the Kullback–Leibler divergences between\n",
    "        the posterior distributions and their priors\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    call : tensorflow.Tensor\n",
    "        Perform the forward pass of the data through\n",
    "        the layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_in, d_out, name=None):\n",
    "        \n",
    "        super(BayesianDenseLayer, self).__init__(name=name)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        \n",
    "        self.w_loc = tf.Variable(xavier([d_in, d_out]), name='w_loc')\n",
    "        self.w_std = tf.Variable(xavier([d_in, d_out])-6.0, name='w_std')\n",
    "        self.b_loc = tf.Variable(xavier([1, d_out]), name='b_loc')\n",
    "        self.b_std = tf.Variable(xavier([1, d_out])-6.0, name='b_std')\n",
    "    \n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Perform the forward pass\"\"\"\n",
    "        \n",
    "        if sampling:\n",
    "        \n",
    "            # Flipout-estimated weight samples\n",
    "            s = random_rademacher(tf.shape(x))\n",
    "            r = random_rademacher([x.shape[0], self.d_out])\n",
    "            w_samples = tf.nn.softplus(self.w_std)*tf.random.normal([self.d_in, self.d_out])\n",
    "            w_perturbations = r*tf.matmul(x*s, w_samples)\n",
    "            w_outputs = tf.matmul(x, self.w_loc) + w_perturbations\n",
    "            \n",
    "            # Flipout-estimated bias samples\n",
    "            r = random_rademacher([x.shape[0], self.d_out])\n",
    "            b_samples = tf.nn.softplus(self.b_std)*tf.random.normal([self.d_out])\n",
    "            b_outputs = self.b_loc + r*b_samples\n",
    "            \n",
    "            return w_outputs + b_outputs\n",
    "        \n",
    "        else:\n",
    "            return x @ self.w_loc + self.b_loc\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        weight = tfd.Normal(self.w_loc, tf.nn.softplus(self.w_std))\n",
    "        bias = tfd.Normal(self.b_loc, tf.nn.softplus(self.b_std))\n",
    "        prior = tfd.Normal(0, 1)\n",
    "        return (tf.reduce_sum(tfd.kl_divergence(weight, prior)) +\n",
    "                tf.reduce_sum(tfd.kl_divergence(bias, prior)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42790a2e-a62e-4b32-9962-9f48b2db4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDenseNetwork(tf.keras.Model):\n",
    "    \"\"\"A multilayer fully-connected Bayesian neural network\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : List[int]\n",
    "        List of units in each layer\n",
    "    name : str\n",
    "        Name for the network\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    losses : tensorflow.Tensor\n",
    "        Sum of the Kullback–Leibler divergences between\n",
    "        the posterior distributions and their priors, \n",
    "        over all layers in the network\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    call : tensorflow.Tensor\n",
    "        Perform the forward pass of the data through\n",
    "        the network\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dims, name=None):\n",
    "        \n",
    "        super(BayesianDenseNetwork, self).__init__(name=name)\n",
    "        \n",
    "        self.steps = []\n",
    "        self.acts = []\n",
    "        for i in range(len(dims)-1):\n",
    "            self.steps += [BayesianDenseLayer(dims[i], dims[i+1])]\n",
    "            self.acts += [tf.nn.relu]\n",
    "            \n",
    "        self.acts[-1] = lambda x: x\n",
    "        \n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Perform the forward pass\"\"\"\n",
    "\n",
    "        for i in range(len(self.steps)):\n",
    "            x = self.steps[i](x, sampling=sampling)\n",
    "            x = self.acts[i](x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        return tf.reduce_sum([s.losses for s in self.steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a029ef6-4427-45ab-9b25-7b2995b30d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDenseRegression(tf.keras.Model):\n",
    "    \"\"\"A multilayer Bayesian neural network regression\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : List[int]\n",
    "        List of units in each layer\n",
    "    name : str\n",
    "        Name for the network\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    losses : tensorflow.Tensor\n",
    "        Sum of the Kullback–Leibler divergences between\n",
    "        the posterior distributions and their priors, \n",
    "        over all layers in the network\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    call : tensorflow.Tensor\n",
    "        Perform the forward pass of the data through\n",
    "        the network, predicting both means and stds\n",
    "    log_likelihood : tensorflow.Tensor\n",
    "        Compute the log likelihood of y given x\n",
    "    samples : tensorflow.Tensor\n",
    "        Draw multiple samples from the predictive distribution\n",
    "    \"\"\"    \n",
    "    \n",
    "    \n",
    "    def __init__(self, dims, name=None):\n",
    "        \n",
    "        super(BayesianDenseRegression, self).__init__(name=name)\n",
    "        \n",
    "        # Multilayer fully-connected neural network to predict mean\n",
    "        self.loc_net = BayesianDenseNetwork(dims)\n",
    "        \n",
    "        # Variational distribution variables for observation error\n",
    "        self.std_alpha = tf.Variable([10.0], name='std_alpha')\n",
    "        self.std_beta = tf.Variable([10.0], name='std_beta')\n",
    "\n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Perform forward pass, predicting both means + stds\"\"\"\n",
    "        \n",
    "        # Predict means\n",
    "        loc_preds = self.loc_net(x, sampling=sampling)\n",
    "    \n",
    "        # Predict std deviation\n",
    "        posterior = tfd.Gamma(self.std_alpha, self.std_beta)\n",
    "        transform = lambda x: tf.sqrt(tf.math.reciprocal(x))\n",
    "        N = x.shape[0]\n",
    "        if sampling:\n",
    "            std_preds = transform(posterior.sample([N]))\n",
    "        else:\n",
    "            std_preds = tf.ones([N, 1])*transform(posterior.mean())\n",
    "    \n",
    "        # Return mean and std predictions\n",
    "        return tf.concat([loc_preds, std_preds], 1)\n",
    "    \n",
    "    \n",
    "    def log_likelihood(self, x, y, sampling=True):\n",
    "        \"\"\"Compute the log likelihood of y given x\"\"\"\n",
    "        \n",
    "        # Compute mean and std predictions\n",
    "        preds = self.call(x, sampling=sampling)\n",
    "        \n",
    "        # Return log likelihood of true data given predictions\n",
    "        return tfd.Normal(preds[:,0], preds[:,1]).log_prob(y[:,0])\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def sample(self, x):\n",
    "        \"\"\"Draw one sample from the predictive distribution\"\"\"\n",
    "        preds = self.call(x)\n",
    "        return tfd.Normal(preds[:,0], preds[:,1]).sample()\n",
    "    \n",
    "    \n",
    "    def samples(self, x, n_samples=1):\n",
    "        \"\"\"Draw multiple samples from the predictive distribution\"\"\"\n",
    "        samples = np.zeros((x.shape[0], n_samples))\n",
    "        for i in range(n_samples):\n",
    "            samples[:,i] = self.sample(x)\n",
    "        return samples\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "                \n",
    "        # Loss due to network weights\n",
    "        net_loss = self.loc_net.losses\n",
    "\n",
    "        # Loss due to std deviation parameter\n",
    "        posterior = tfd.Gamma(self.std_alpha, self.std_beta)\n",
    "        prior = tfd.Gamma(10.0, 10.0)\n",
    "        std_loss = tfd.kl_divergence(posterior, prior)\n",
    "\n",
    "        # Return the sum of both\n",
    "        return net_loss + std_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e9eeea-63e7-4ef1-a8f3-105665e256be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BayesianDenseRegression([7, 256, 128, 64, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d60722-8a18-4394-afeb-783aa8a803b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS Zephyrus G15\\CSCI\\jin\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=L_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79592a7-42d9-40ed-bc44-5adb8df088c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x_train.shape[0]\n",
    "\n",
    "@tf.function\n",
    "def train_step(x_data, y_data):\n",
    "    with tf.GradientTape() as tape:\n",
    "        log_likelihoods = model1.log_likelihood(x_data, y_data)\n",
    "        kl_loss = model1.losses\n",
    "        elbo_loss = kl_loss/N - tf.reduce_mean(log_likelihoods)\n",
    "    gradients = tape.gradient(elbo_loss, model1.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model1.trainable_variables))\n",
    "    return elbo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "800b73c7-4be5-47f3-996b-765eb16bf18c",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make a TensorFlow Dataset from training data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m N_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m data_train \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(N_train )\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:781\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \n\u001b[0;32m    707\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 781\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4661\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[1;34m(self, element, is_files, name)\u001b[0m\n\u001b[0;32m   4659\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   4660\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4661\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4662\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m   4663\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:129\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    126\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    128\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 129\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1621\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1616\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1617\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1618\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1621\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1624\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\CSCI\\jin\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Make a TensorFlow Dataset from training data\n",
    "N_train = x_train.shape[0]\n",
    "data_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(N_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e586a60-7c0e-4824-a1ad-1b0a366c1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_val = x_val.shape[0]\n",
    "data_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(N_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de1024f9-0601-4c25-bb93-801338700e28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m mae1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(EPOCHS)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Update weights each batch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_data, y_data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_train\u001b[49m:\n\u001b[0;32m      8\u001b[0m         elbo1[epoch] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_step(x_data, y_data)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Evaluate performance on validation data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "elbo1 = np.zeros(EPOCHS)\n",
    "mae1 = np.zeros(EPOCHS)\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Update weights each batch\n",
    "    for x_data, y_data in data_train:\n",
    "        elbo1[epoch] += train_step(x_data, y_data)\n",
    "        \n",
    "    # Evaluate performance on validation data\n",
    "    for x_data, y_data in data_val:\n",
    "        y_pred = model1(x_data, sampling=False)[:, 0]\n",
    "        mae1[epoch] = mean_absolute_error(y_pred, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d34cbf5-14a3-444a-b93c-79203ac70cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ELBO loss\n",
    "plt.plot(elbo1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ELBO Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6031c7ac-f658-432d-90e4-5ea5153fff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot validation error over training\n",
    "plt.plot(mae1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b324509-de09-4c93-9ef3-7a15544970b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
