{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18095ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506ddb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1INCHBUSD_open</th>\n",
       "      <th>1INCHBUSD_high</th>\n",
       "      <th>1INCHBUSD_low</th>\n",
       "      <th>1INCHBUSD_close</th>\n",
       "      <th>1INCHBUSD_volume</th>\n",
       "      <th>1INCHUSD_open</th>\n",
       "      <th>1INCHUSD_high</th>\n",
       "      <th>1INCHUSD_low</th>\n",
       "      <th>1INCHUSD_close</th>\n",
       "      <th>1INCHUSD_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>ZRXBUSD_open</th>\n",
       "      <th>ZRXBUSD_high</th>\n",
       "      <th>ZRXBUSD_low</th>\n",
       "      <th>ZRXBUSD_close</th>\n",
       "      <th>ZRXBUSD_volume</th>\n",
       "      <th>ZRXUSD_open</th>\n",
       "      <th>ZRXUSD_high</th>\n",
       "      <th>ZRXUSD_low</th>\n",
       "      <th>ZRXUSD_close</th>\n",
       "      <th>ZRXUSD_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>2.410</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.406</td>\n",
       "      <td>2.429</td>\n",
       "      <td>27034.1</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.42</td>\n",
       "      <td>47726.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8349</td>\n",
       "      <td>2957.0</td>\n",
       "      <td>0.803274</td>\n",
       "      <td>0.815819</td>\n",
       "      <td>0.803274</td>\n",
       "      <td>0.815819</td>\n",
       "      <td>124094.48027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 01:00:00</th>\n",
       "      <td>2.434</td>\n",
       "      <td>2.441</td>\n",
       "      <td>2.421</td>\n",
       "      <td>2.424</td>\n",
       "      <td>15641.5</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.44</td>\n",
       "      <td>109643.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>7690.0</td>\n",
       "      <td>0.815761</td>\n",
       "      <td>0.818488</td>\n",
       "      <td>0.812232</td>\n",
       "      <td>0.816939</td>\n",
       "      <td>430003.38704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 02:00:00</th>\n",
       "      <td>2.423</td>\n",
       "      <td>2.444</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.434</td>\n",
       "      <td>10500.5</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.44</td>\n",
       "      <td>22534.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>0.8249</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>0.817332</td>\n",
       "      <td>0.841967</td>\n",
       "      <td>0.816370</td>\n",
       "      <td>0.825341</td>\n",
       "      <td>545121.67633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 03:00:00</th>\n",
       "      <td>2.433</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.433</td>\n",
       "      <td>2.435</td>\n",
       "      <td>11621.9</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.43</td>\n",
       "      <td>16066.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>5814.0</td>\n",
       "      <td>0.825479</td>\n",
       "      <td>0.826189</td>\n",
       "      <td>0.819242</td>\n",
       "      <td>0.821205</td>\n",
       "      <td>174704.12975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 04:00:00</th>\n",
       "      <td>2.436</td>\n",
       "      <td>2.454</td>\n",
       "      <td>2.415</td>\n",
       "      <td>2.428</td>\n",
       "      <td>18122.9</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>35143.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.8239</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>4731.0</td>\n",
       "      <td>0.822383</td>\n",
       "      <td>0.824401</td>\n",
       "      <td>0.814999</td>\n",
       "      <td>0.821184</td>\n",
       "      <td>109516.28991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1955 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1INCHBUSD_open  1INCHBUSD_high  1INCHBUSD_low  \\\n",
       "datetime                                                             \n",
       "2022-01-01 00:00:00           2.410           2.450          2.406   \n",
       "2022-01-01 01:00:00           2.434           2.441          2.421   \n",
       "2022-01-01 02:00:00           2.423           2.444          2.418   \n",
       "2022-01-01 03:00:00           2.433           2.449          2.433   \n",
       "2022-01-01 04:00:00           2.436           2.454          2.415   \n",
       "\n",
       "                     1INCHBUSD_close  1INCHBUSD_volume  1INCHUSD_open  \\\n",
       "datetime                                                                \n",
       "2022-01-01 00:00:00            2.429           27034.1           2.39   \n",
       "2022-01-01 01:00:00            2.424           15641.5           2.42   \n",
       "2022-01-01 02:00:00            2.434           10500.5           2.43   \n",
       "2022-01-01 03:00:00            2.435           11621.9           2.43   \n",
       "2022-01-01 04:00:00            2.428           18122.9           2.42   \n",
       "\n",
       "                     1INCHUSD_high  1INCHUSD_low  1INCHUSD_close  \\\n",
       "datetime                                                           \n",
       "2022-01-01 00:00:00           2.42          2.39            2.42   \n",
       "2022-01-01 01:00:00           2.44          2.41            2.44   \n",
       "2022-01-01 02:00:00           2.45          2.43            2.44   \n",
       "2022-01-01 03:00:00           2.45          2.43            2.43   \n",
       "2022-01-01 04:00:00           2.43          2.40            2.40   \n",
       "\n",
       "                     1INCHUSD_volume  ...  ZRXBUSD_open  ZRXBUSD_high  \\\n",
       "datetime                              ...                               \n",
       "2022-01-01 00:00:00         47726.30  ...        0.8225        0.8375   \n",
       "2022-01-01 01:00:00        109643.15  ...        0.8367        0.8367   \n",
       "2022-01-01 02:00:00         22534.85  ...        0.8249        0.8305   \n",
       "2022-01-01 03:00:00         16066.99  ...        0.8310        0.8327   \n",
       "2022-01-01 04:00:00         35143.16  ...        0.8262        0.8326   \n",
       "\n",
       "                     ZRXBUSD_low  ZRXBUSD_close  ZRXBUSD_volume  ZRXUSD_open  \\\n",
       "datetime                                                                       \n",
       "2022-01-01 00:00:00       0.8225         0.8349          2957.0     0.803274   \n",
       "2022-01-01 01:00:00       0.8262         0.8262          7690.0     0.815761   \n",
       "2022-01-01 02:00:00       0.8249         0.8296          1352.0     0.817332   \n",
       "2022-01-01 03:00:00       0.8271         0.8271          5814.0     0.825479   \n",
       "2022-01-01 04:00:00       0.8239         0.8326          4731.0     0.822383   \n",
       "\n",
       "                     ZRXUSD_high  ZRXUSD_low  ZRXUSD_close  ZRXUSD_volume  \n",
       "datetime                                                                   \n",
       "2022-01-01 00:00:00     0.815819    0.803274      0.815819   124094.48027  \n",
       "2022-01-01 01:00:00     0.818488    0.812232      0.816939   430003.38704  \n",
       "2022-01-01 02:00:00     0.841967    0.816370      0.825341   545121.67633  \n",
       "2022-01-01 03:00:00     0.826189    0.819242      0.821205   174704.12975  \n",
       "2022-01-01 04:00:00     0.824401    0.814999      0.821184   109516.28991  \n",
       "\n",
       "[5 rows x 1955 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/flattened_data.csv\", index_col = \"datetime\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746156e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2537, 1955)\n",
      "Validation set shape: (544, 1955)\n",
      "Test data set: (543, 1955)\n",
      "Training set shape (2507, 30, 1955) (2507, 1955)\n",
      "Validation set shape (514, 30, 1955) (514, 1955)\n",
      "Testing set shape (513, 30, 1955) (513, 1955)\n"
     ]
    }
   ],
   "source": [
    "## split the dataset into 70:15:15\n",
    "last_15 = sorted(df.index.values)[-int(0.15*len(df))] # Last 15% indices\n",
    "last_30 = sorted(df.index.values)[-int(0.3*len(df))] \n",
    "\n",
    "train_data = df[(df.index < last_30)].values\n",
    "val_data = df[(df.index >= last_30) & (df.index < last_15)].values\n",
    "test_data = df[(df.index >= last_15)].values\n",
    "\n",
    "print('Training set shape: {}'.format(train_data.shape))\n",
    "print('Validation set shape: {}'.format(val_data.shape))\n",
    "print('Test data set: {}'.format(test_data.shape))\n",
    "# standardize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "val_data = scaler.transform(val_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "# reshape the data with to window size\n",
    "seq_len = 30\n",
    "\n",
    "def reshape_data(seq_len, data):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_len, len(data)):\n",
    "        X.append(data[i-seq_len:i])\n",
    "        y.append(data[:][i])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = reshape_data(seq_len, train_data)\n",
    "X_val, y_val = reshape_data(seq_len, val_data)\n",
    "X_test, y_test = reshape_data(seq_len, test_data)\n",
    "\n",
    "print('Training set shape', X_train.shape, y_train.shape)\n",
    "print('Validation set shape', X_val.shape, y_val.shape)\n",
    "print('Testing set shape' ,X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78733e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 1955)\n",
      "(513, 391)\n",
      "(513, 391)\n",
      "-491293.0070585426\n"
     ]
    }
   ],
   "source": [
    "profit = 0\n",
    "x_test_last = X_test[:, -1, :]\n",
    "\n",
    "# TODO, trading decisions - profit\n",
    "print(x_test_last.shape)\n",
    "x_test_last_close = []\n",
    "y_test_close = []\n",
    "y_test_pred_close = []\n",
    "for i in range(x_test_last.shape[1]):\n",
    "    if i%5 == 3:\n",
    "        x_test_last_close.append(x_test_last[:,i])\n",
    "        y_test_close.append(y_test[:,i])\n",
    "        # y_test_pred_close.append(y_test_pred[:,i])\n",
    "x_test_last_close = np.transpose(np.array(x_test_last_close))\n",
    "y_test_close = np.transpose(np.array(y_test_close))\n",
    "# y_test_pred_close = np.transpose(np.array(y_test_pred_close))\n",
    "print(x_test_last_close.shape)\n",
    "print(y_test_close.shape)\n",
    "# print(y_test_pred_close.shape)\n",
    "\n",
    "\n",
    "for i in range(x_test_last_close.shape[0]):\n",
    "    for j in range(x_test_last_close.shape[1]):\n",
    "        if x_test_last_close[i,j] != 0:\n",
    "            profit = profit - 1000 + 1000*(y_test_close[i, j]/x_test_last_close[i,j])\n",
    "print(profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed5b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = 128\n",
    "d_v = 128\n",
    "n_heads = 8\n",
    "ff_dim = 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89cd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T2V(Layer):\n",
    "    def __init__(self, output_dim=None, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(T2V, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='W',\n",
    "                      shape=(input_shape[-1], self.output_dim),\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "        self.P = self.add_weight(name='P',\n",
    "                      shape=(input_shape[1], self.output_dim),\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "        self.w = self.add_weight(name='w',\n",
    "                      shape=(input_shape[1], 1),\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "        self.p = self.add_weight(name='p',\n",
    "                      shape=(input_shape[1], 1),\n",
    "                      initializer='uniform',\n",
    "                      trainable=True)\n",
    "        super(T2V, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        original = self.w * x + self.p\n",
    "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
    "        \n",
    "        return K.concatenate([sin_trans, original], -1)\n",
    "    \n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'output_dim': self.output_dim})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c67e87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttention(Layer):\n",
    "    def __init__(self, d_k, d_v):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "        self.key = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "        self.value = Dense(self.d_v, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "    \n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = tf.matmul(attn_weights, v)\n",
    "        return attn_out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fee3f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttention(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.attn_heads = list()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        for n in range(self.n_heads):\n",
    "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))\n",
    "            self.linear = Dense(input_shape[0][-1], input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "        concat_attn = tf.concat(attn, axis=-1)\n",
    "        multi_linear = self.linear(concat_attn)\n",
    "        return multi_linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "476da4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.attn_heads = list()\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "        self.attn_dropout = Dropout(self.dropout_rate)\n",
    "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "        # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \n",
    "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
    "        self.ff_dropout = Dropout(self.dropout_rate)\n",
    "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
    "  \n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        attn_layer = self.attn_multi(inputs)\n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer \n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'d_k': self.d_k,\n",
    "                       'd_v': self.d_v,\n",
    "                       'n_heads': self.n_heads,\n",
    "                       'ff_dim': self.ff_dim,\n",
    "                       'attn_heads': self.attn_heads,\n",
    "                       'dropout_rate': self.dropout_rate})\n",
    "        return config      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29af2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''Initialize time and transformer layers'''\n",
    "    time_embedding = T2V(seq_len)\n",
    "    attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "    '''Construct model'''\n",
    "    in_seq = Input(shape=(seq_len, 1955))\n",
    "    x = time_embedding(in_seq)\n",
    "    x = Concatenate(axis=-1)([in_seq, x])\n",
    "    x = attn_layer1((x, x, x))\n",
    "    x = attn_layer2((x, x, x))\n",
    "    x = attn_layer3((x, x, x))\n",
    "    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.15)(x)\n",
    "    out = Dense(1955)(x)\n",
    "\n",
    "    model = Model(inputs=in_seq, outputs=out)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa990c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 1955)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "t2v (T2V)                       (None, 30, 1985)     59610       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 3940)     0           input_1[0][0]                    \n",
      "                                                                 t2v[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, 30, 3940)     17173720    concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_1 (Transfor (None, 30, 3940)     17173720    transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_2 (Transfor (None, 30, 3940)     17173720    transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 30)           0           transformer_encoder_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30)           0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          3968        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1955)         252195      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 51,836,933\n",
      "Trainable params: 51,836,933\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd4f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.ModelCheckpoint('Transformer+TimeEmbedding.hdf5', \n",
    "                                              monitor='val_loss', \n",
    "                                              save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7fa6481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 95s 2s/step - loss: 0.1049 - mae: 0.2351 - mse: 0.1049 - val_loss: 0.0630 - val_mae: 0.1941 - val_mse: 0.0630\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06303, saving model to Transformer+TimeEmbedding.hdf5\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 82s 2s/step - loss: 0.0323 - mae: 0.1315 - mse: 0.0323 - val_loss: 0.0388 - val_mae: 0.1336 - val_mse: 0.0388\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06303 to 0.03884, saving model to Transformer+TimeEmbedding.hdf5\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 81s 2s/step - loss: 0.0202 - mae: 0.1014 - mse: 0.0202 - val_loss: 0.0361 - val_mae: 0.1252 - val_mse: 0.0361\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03884 to 0.03611, saving model to Transformer+TimeEmbedding.hdf5\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 81s 2s/step - loss: 0.0151 - mae: 0.0856 - mse: 0.0151 - val_loss: 0.0323 - val_mae: 0.1177 - val_mse: 0.0323\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03611 to 0.03230, saving model to Transformer+TimeEmbedding.hdf5\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 83s 2s/step - loss: 0.0126 - mae: 0.0775 - mse: 0.0126 - val_loss: 0.0294 - val_mae: 0.1065 - val_mse: 0.0294\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03230 to 0.02939, saving model to Transformer+TimeEmbedding.hdf5\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 81s 2s/step - loss: 0.0120 - mae: 0.0748 - mse: 0.0120 - val_loss: 0.0300 - val_mae: 0.1096 - val_mse: 0.0300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02939\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 82s 2s/step - loss: 0.0118 - mae: 0.0745 - mse: 0.0118 - val_loss: 0.0296 - val_mae: 0.1077 - val_mse: 0.0296\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02939\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 82s 2s/step - loss: 0.0111 - mae: 0.0722 - mse: 0.0111 - val_loss: 0.0311 - val_mae: 0.1104 - val_mse: 0.0311\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02939\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 82s 2s/step - loss: 0.0109 - mae: 0.0720 - mse: 0.0109 - val_loss: 0.0320 - val_mae: 0.1139 - val_mse: 0.0320\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02939\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 82s 2s/step - loss: 0.0109 - mae: 0.0722 - mse: 0.0109 - val_loss: 0.0328 - val_mae: 0.1163 - val_mse: 0.0328\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02939\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=10, \n",
    "                    callbacks=[callback],\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24d25037",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('Transformer+TimeEmbedding.hdf5',\n",
    "                                   custom_objects={'T2V': T2V,\n",
    "                                                   'SingleAttention': SingleAttention,\n",
    "                                                   'MultiAttention': MultiAttention,\n",
    "                                                   'TransformerEncoder': TransformerEncoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e684846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe3ceaa4cd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.yscale('log')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Log Loss over Epochs')\n",
    "\n",
    "plt.legend(['loss', 'validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc51e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.284448623657227, 0.36135610938072205, 4.284448623657227]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca66c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8a80901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2507, 1955) (513, 1955)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_pred.shape, y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75127855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_array = []\n",
    "for i in range(y_test.shape[1]):\n",
    "    r2_array.append(r2_score(np.array(y_test[:, i]), np.array(y_test_pred[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e007fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value of the r2 array: -116.49601394106007\n",
      "median value of the r2 array: -84.72204589342324\n"
     ]
    }
   ],
   "source": [
    "print('mean value of the r2 array:', np.mean(r2_array))\n",
    "print('median value of the r2 array:', np.median(r2_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1788bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 1955)\n",
      "(513, 391)\n",
      "(513, 391)\n",
      "(513, 391)\n",
      "-358286.2365630365\n"
     ]
    }
   ],
   "source": [
    "profit = 0\n",
    "X_test_last = X_test[:, -1, :]\n",
    "\n",
    "# TODO, trading decisions - profit\n",
    "print(X_test_last.shape)\n",
    "X_test_last_close = []\n",
    "y_test_close = []\n",
    "y_test_pred_close = []\n",
    "for i in range(X_test_last.shape[1]):\n",
    "    if i%5 == 3:\n",
    "        X_test_last_close.append(X_test_last[:,i])\n",
    "        y_test_close.append(y_test[:,i])\n",
    "        y_test_pred_close.append(y_test_pred[:,i])\n",
    "X_test_last_close = np.transpose(np.array(X_test_last_close))\n",
    "y_test_close = np.transpose(np.array(y_test_close))\n",
    "y_test_pred_close = np.transpose(np.array(y_test_pred_close))\n",
    "print(x_test_last_close.shape)\n",
    "print(y_test_close.shape)\n",
    "print(y_test_pred_close.shape)\n",
    "\n",
    "\n",
    "for i in range(X_test_last_close.shape[0]):\n",
    "    for j in range(X_test_last_close.shape[1]):\n",
    "        if X_test_last_close[i,j] != 0 and y_test_pred_close[i, j] > X_test_last_close[i, j]:\n",
    "            profit = profit - 1000 + 1000*(y_test_close[i, j]/X_test_last_close[i,j])\n",
    "print(profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f8e5c",
   "metadata": {},
   "source": [
    "baseline profit: -491293.0070585426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ad97c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "133e1aa1ab932592a172947296ac0a44a4189561742e82da493ac43542eab238"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
